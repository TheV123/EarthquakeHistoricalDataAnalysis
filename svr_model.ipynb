{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal of this file is to create a simple model and see if it is possible to see likelyhood of a large earthquake - using ETAS and then using USGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Year</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Z\\r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/31/59</td>\n",
       "      <td>0:03:09.00</td>\n",
       "      <td>1960.002196</td>\n",
       "      <td>-119.0502</td>\n",
       "      <td>33.9790</td>\n",
       "      <td>6.50</td>\n",
       "      <td>8.2474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/2/60</td>\n",
       "      <td>0:08:49.00</td>\n",
       "      <td>1960.006125</td>\n",
       "      <td>-115.6222</td>\n",
       "      <td>33.0793</td>\n",
       "      <td>4.25</td>\n",
       "      <td>7.9322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/2/60</td>\n",
       "      <td>0:10:31.00</td>\n",
       "      <td>1960.007305</td>\n",
       "      <td>-115.6323</td>\n",
       "      <td>33.1220</td>\n",
       "      <td>3.03</td>\n",
       "      <td>8.4015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/2/60</td>\n",
       "      <td>0:10:32.00</td>\n",
       "      <td>1960.007320</td>\n",
       "      <td>-115.5851</td>\n",
       "      <td>33.0745</td>\n",
       "      <td>3.03</td>\n",
       "      <td>7.9678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/2/60</td>\n",
       "      <td>0:11:07.00</td>\n",
       "      <td>1960.007720</td>\n",
       "      <td>-115.6256</td>\n",
       "      <td>33.0290</td>\n",
       "      <td>3.08</td>\n",
       "      <td>7.9737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date        Time         Year         X        Y  Magnitude     Z\\r\n",
       "0  12/31/59  0:03:09.00  1960.002196 -119.0502  33.9790       6.50  8.2474\n",
       "1    1/2/60  0:08:49.00  1960.006125 -115.6222  33.0793       4.25  7.9322\n",
       "2    1/2/60  0:10:31.00  1960.007305 -115.6323  33.1220       3.03  8.4015\n",
       "3    1/2/60  0:10:32.00  1960.007320 -115.5851  33.0745       3.03  7.9678\n",
       "4    1/2/60  0:11:07.00  1960.007720 -115.6256  33.0290       3.08  7.9737"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = \"Formatted_ETAS_Output.csv\"\n",
    "etas = pd.read_csv(csv_file, sep = ',', lineterminator='\\n')\n",
    "etas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Year</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Z\\r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1959-12-31</td>\n",
       "      <td>0:03:09.00</td>\n",
       "      <td>1960.002196</td>\n",
       "      <td>-119.0502</td>\n",
       "      <td>33.9790</td>\n",
       "      <td>6.50</td>\n",
       "      <td>8.2474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1960-01-02</td>\n",
       "      <td>0:08:49.00</td>\n",
       "      <td>1960.006125</td>\n",
       "      <td>-115.6222</td>\n",
       "      <td>33.0793</td>\n",
       "      <td>4.25</td>\n",
       "      <td>7.9322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1960-01-02</td>\n",
       "      <td>0:10:31.00</td>\n",
       "      <td>1960.007305</td>\n",
       "      <td>-115.6323</td>\n",
       "      <td>33.1220</td>\n",
       "      <td>3.03</td>\n",
       "      <td>8.4015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960-01-02</td>\n",
       "      <td>0:10:32.00</td>\n",
       "      <td>1960.007320</td>\n",
       "      <td>-115.5851</td>\n",
       "      <td>33.0745</td>\n",
       "      <td>3.03</td>\n",
       "      <td>7.9678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960-01-02</td>\n",
       "      <td>0:11:07.00</td>\n",
       "      <td>1960.007720</td>\n",
       "      <td>-115.6256</td>\n",
       "      <td>33.0290</td>\n",
       "      <td>3.08</td>\n",
       "      <td>7.9737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        Time         Year         X        Y  Magnitude     Z\\r\n",
       "0 1959-12-31  0:03:09.00  1960.002196 -119.0502  33.9790       6.50  8.2474\n",
       "1 1960-01-02  0:08:49.00  1960.006125 -115.6222  33.0793       4.25  7.9322\n",
       "2 1960-01-02  0:10:31.00  1960.007305 -115.6323  33.1220       3.03  8.4015\n",
       "3 1960-01-02  0:10:32.00  1960.007320 -115.5851  33.0745       3.03  7.9678\n",
       "4 1960-01-02  0:11:07.00  1960.007720 -115.6256  33.0290       3.08  7.9737"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting the Date column into datetime format\n",
    "etas[\"Date\"] = pd.to_datetime(etas[\"Date\"], errors=\"coerce\", format=\"%m/%d/%y\")\n",
    "etas.loc[etas[\"Date\"].dt.year > pd.Timestamp.now().year, \"Date\"] -= pd.DateOffset(years=100)\n",
    "\n",
    "etas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Year</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Z\\r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1960-01-02</td>\n",
       "      <td>0:08:49.00</td>\n",
       "      <td>1960.006125</td>\n",
       "      <td>-115.6222</td>\n",
       "      <td>33.0793</td>\n",
       "      <td>4.25</td>\n",
       "      <td>7.9322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1960-01-02</td>\n",
       "      <td>0:10:31.00</td>\n",
       "      <td>1960.007305</td>\n",
       "      <td>-115.6323</td>\n",
       "      <td>33.1220</td>\n",
       "      <td>3.03</td>\n",
       "      <td>8.4015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960-01-02</td>\n",
       "      <td>0:10:32.00</td>\n",
       "      <td>1960.007320</td>\n",
       "      <td>-115.5851</td>\n",
       "      <td>33.0745</td>\n",
       "      <td>3.03</td>\n",
       "      <td>7.9678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960-01-02</td>\n",
       "      <td>0:11:07.00</td>\n",
       "      <td>1960.007720</td>\n",
       "      <td>-115.6256</td>\n",
       "      <td>33.0290</td>\n",
       "      <td>3.08</td>\n",
       "      <td>7.9737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1960-01-02</td>\n",
       "      <td>0:11:17.00</td>\n",
       "      <td>1960.007840</td>\n",
       "      <td>-115.6050</td>\n",
       "      <td>33.0276</td>\n",
       "      <td>3.61</td>\n",
       "      <td>7.9322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        Time         Year         X        Y  Magnitude     Z\\r\n",
       "1 1960-01-02  0:08:49.00  1960.006125 -115.6222  33.0793       4.25  7.9322\n",
       "2 1960-01-02  0:10:31.00  1960.007305 -115.6323  33.1220       3.03  8.4015\n",
       "3 1960-01-02  0:10:32.00  1960.007320 -115.5851  33.0745       3.03  7.9678\n",
       "4 1960-01-02  0:11:07.00  1960.007720 -115.6256  33.0290       3.08  7.9737\n",
       "5 1960-01-02  0:11:17.00  1960.007840 -115.6050  33.0276       3.61  7.9322"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter the dataset by Date > 1960-01-01 and Date < 2023-01-1 \n",
    "etas = etas[(etas['Date'] > pd.to_datetime('1960-01-01')) & (etas['Date'] < pd.to_datetime('2023-01-01'))]\n",
    "\n",
    "#filter the dataset by X > -123 and X < -113 and Y > 29 and Y < 39\n",
    "etas = etas[etas['X'] > -123]\n",
    "etas = etas[etas['X'] < -113]\n",
    "etas = etas[etas['Y'] < 39]\n",
    "etas = etas[etas['Y'] > 29]\n",
    "\n",
    "etas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Date        Time          Year             X  \\\n",
      "count                 31547       31547  31547.000000  31547.000000   \n",
      "unique                18880       26489           NaN           NaN   \n",
      "top     1964-04-26 00:00:00  6:49:17.00           NaN           NaN   \n",
      "freq                     10           5           NaN           NaN   \n",
      "first   1960-01-02 00:00:00         NaN           NaN           NaN   \n",
      "last    2022-12-31 00:00:00         NaN           NaN           NaN   \n",
      "mean                    NaN         NaN   1991.704948   -117.520496   \n",
      "std                     NaN         NaN     18.290538      2.080386   \n",
      "min                     NaN         NaN   1960.006125   -122.971200   \n",
      "25%                     NaN         NaN   1975.794142   -118.711750   \n",
      "50%                     NaN         NaN   1992.042660   -117.191400   \n",
      "75%                     NaN         NaN   2007.554579   -116.092200   \n",
      "max                     NaN         NaN   2023.001815   -113.246300   \n",
      "\n",
      "                   Y     Magnitude           Z\\r  \n",
      "count   31547.000000  31547.000000  31547.000000  \n",
      "unique           NaN           NaN           NaN  \n",
      "top              NaN           NaN           NaN  \n",
      "freq             NaN           NaN           NaN  \n",
      "first            NaN           NaN           NaN  \n",
      "last             NaN           NaN           NaN  \n",
      "mean       34.786608      3.452404      9.544947  \n",
      "std         2.370060      0.460174      6.158339  \n",
      "min        29.080400      3.000000      0.000000  \n",
      "25%        33.331600      3.130000      4.172650  \n",
      "50%        34.569000      3.310000      8.984100  \n",
      "75%        36.785400      3.630000     15.042250  \n",
      "max        38.999600      7.650000     20.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vishal\\AppData\\Local\\Temp\\ipykernel_17884\\2667887429.py:1: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  summary_stats = etas.describe(include=\"all\")\n"
     ]
    }
   ],
   "source": [
    "summary_stats = etas.describe(include=\"all\")\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17212   1994-08-25\n",
      "8494    1976-10-01\n",
      "18514   1997-01-04\n",
      "29109   2017-10-10\n",
      "9400    1978-08-06\n",
      "           ...    \n",
      "30007   2019-07-05\n",
      "5393    1970-07-18\n",
      "861     1961-11-19\n",
      "15905   1992-01-31\n",
      "23855   2007-07-17\n",
      "Name: Date, Length: 25237, dtype: datetime64[ns] 822     1961-10-31\n",
      "18419   1996-11-06\n",
      "6385    1972-07-17\n",
      "15797   1991-11-08\n",
      "3755    1967-05-15\n",
      "           ...    \n",
      "21399   2002-10-18\n",
      "20505   2001-01-25\n",
      "26666   2013-06-05\n",
      "5567    1970-11-25\n",
      "3217    1966-06-19\n",
      "Name: Date, Length: 6310, dtype: datetime64[ns] 17212    3.07\n",
      "8494     3.24\n",
      "18514    3.36\n",
      "29109    3.15\n",
      "9400     3.01\n",
      "         ... \n",
      "30007    4.09\n",
      "5393     3.64\n",
      "861      3.33\n",
      "15905    3.13\n",
      "23855    3.34\n",
      "Name: Magnitude, Length: 25237, dtype: float64 822      3.26\n",
      "18419    3.08\n",
      "6385     3.59\n",
      "15797    3.69\n",
      "3755     3.65\n",
      "         ... \n",
      "21399    3.10\n",
      "20505    3.61\n",
      "26666    3.28\n",
      "5567     3.18\n",
      "3217     3.42\n",
      "Name: Magnitude, Length: 6310, dtype: float64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 7.7777280e+17  2.1297600e+17  8.5233600e+17 ... -2.5617600e+17\n  6.9681600e+17  1.1846304e+18].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Vishal\\OneDrive\\Documents\\Programs\\Earthquake Classification\\svr_model.ipynb Cell 7\u001b[0m line \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vishal/OneDrive/Documents/Programs/Earthquake%20Classification/svr_model.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Standardize the features\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vishal/OneDrive/Documents/Programs/Earthquake%20Classification/svr_model.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Vishal/OneDrive/Documents/Programs/Earthquake%20Classification/svr_model.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_train \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mfit_transform(X_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vishal/OneDrive/Documents/Programs/Earthquake%20Classification/svr_model.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_test \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(X_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vishal/OneDrive/Documents/Programs/Earthquake%20Classification/svr_model.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Create and train the SVR model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Vishal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Vishal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\Vishal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:837\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    835\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    836\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 837\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\Vishal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Vishal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:873\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[39m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \n\u001b[0;32m    843\u001b[0m \u001b[39mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[39m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    872\u001b[0m first_call \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 873\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    874\u001b[0m     X,\n\u001b[0;32m    875\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    876\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    877\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    878\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_call,\n\u001b[0;32m    879\u001b[0m )\n\u001b[0;32m    880\u001b[0m n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    882\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Vishal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\Vishal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:940\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    939\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 940\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    941\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    942\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    943\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    945\u001b[0m         )\n\u001b[0;32m    947\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(array\u001b[39m.\u001b[39mdtype, \u001b[39m\"\u001b[39m\u001b[39mkind\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    948\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    949\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    950\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    951\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 7.7777280e+17  2.1297600e+17  8.5233600e+17 ... -2.5617600e+17\n  6.9681600e+17  1.1846304e+18].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(etas[\"Date\"], etas[\"Magnitude\"], test_size=0.2, random_state=42)\n",
    "print(X_train, X_test, y_train, y_test)\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create and train the SVR model\n",
    "svr = SVR(kernel='rbf', C=1.0, epsilon=0.2)\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Predict earthquake magnitudes\n",
    "y_pred = svr.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
